# ğŸ¬ Roteiro do VÃ­deo â€” Fase 2 Tech Challenge FIAP

## IntroduÃ§Ã£o (~1 min)

> "Bom dia, galera! Tudo bem? Me chamo **Matheus Nogueira** e hoje estou gravando esse vÃ­deo referente Ã  **Fase 2 do desafio Tech Challenge** da pÃ³s-graduaÃ§Ã£o de **Arquitetura de Software na FIAP**.
>
> Nessa fase, o objetivo era **containerizar nossa aplicaÃ§Ã£o**, fazer a **orquestraÃ§Ã£o com Kubernetes**, provisionar a **infraestrutura como cÃ³digo** usando Terraform, e montar um **pipeline de CI/CD** completo.
>
> EntÃ£o hoje vou mostrar pra vocÃªs como tÃ¡ tudo funcionando na prÃ¡tica â€” vamos **deployar a aplicaÃ§Ã£o no AWS EKS** e fazer um **teste de carga ao vivo** para mostrar o **autoscaling** do Kubernetes em aÃ§Ã£o."

---

## Parte 1 â€” VisÃ£o Geral da Arquitetura (~2 min)

> "Antes de ir pro terminal, deixa eu explicar rapidamente a arquitetura:"

### Pontos para mencionar:
- **API:** Go (Golang) com Chi Router, PostgreSQL, JWT Auth
- **Docker:** Multi-stage build, imagem otimizada para produÃ§Ã£o
- **Kubernetes:** Deployment, Service (LoadBalancer), HPA (Horizontal Pod Autoscaler)
- **Infraestrutura (Terraform):** VPC, EKS Cluster, RDS PostgreSQL, ECR (registry de imagens)
- **CI/CD (GitHub Actions):** Build â†’ Lint â†’ Testes â†’ Push para ECR â†’ Deploy no EKS

> "Toda a infraestrutura Ã© provisionada com **Terraform**, zero configuraÃ§Ã£o manual. O pipeline do GitHub Actions faz o build, roda os testes, faz o push da imagem Docker pro ECR da AWS, e faz o deploy automÃ¡tico no cluster EKS."

---

## Parte 2 â€” Mostrando a Infra Provisionada (~2 min)

### Comandos para mostrar:

```bash
# Verificar o cluster EKS
kubectl get nodes
```
> "Aqui vemos que o cluster EKS estÃ¡ ativo, com **1 node** rodando Kubernetes **v1.29**."

```bash
# Verificar os pods da aplicaÃ§Ã£o
kubectl get pods -n autorepair
```
> "Nosso deployment criou **2 rÃ©plicas** da API, as duas com status **Running**."

```bash
# Verificar o service (LoadBalancer)
kubectl get svc -n autorepair
```
> "Temos um **LoadBalancer** que expÃµe a API para a internet com uma URL pÃºblica da AWS."

```bash
# Verificar o HPA (autoscaling)
kubectl get hpa -n autorepair
```
> "E aqui temos o **HPA (Horizontal Pod Autoscaler)** configurado para escalar entre **2 e 10 rÃ©plicas**, baseado no uso de **CPU e memÃ³ria**."

```bash
# Health check da API pelo LoadBalancer
curl http://<URL_DO_LOADBALANCER>/health
```
> "E fazendo um health check, a API retorna `status: ok` â€” tudo funcionando!"

---

## Parte 3 â€” Pipeline CI/CD (~1 min)

> "Agora vou mostrar rapidamente o pipeline no GitHub Actions."

### Mostrar no navegador:
- Abrir o repositÃ³rio no GitHub â†’ aba **Actions**
- Mostrar o Ãºltimo workflow executado com os 3 jobs:
  1. âœ… **build-and-test** â€” lint (golangci-lint), testes unitÃ¡rios com cobertura
  2. âœ… **docker-build-push** â€” build da imagem Docker e push para o ECR
  3. âœ… **deploy** â€” kubectl apply dos manifestos e deploy no EKS

> "Toda vez que fazemos um push na branch `main`, o pipeline roda automaticamente: faz o lint, os testes, builda a imagem Docker, faz o push pro ECR, e deploya no cluster. **Zero intervenÃ§Ã£o manual.**"

---

## Parte 4 â€” DemonstraÃ§Ã£o do Autoscaling (~3 min)

> "Agora a parte mais legal: vamos simular um **teste de carga** e ver o **autoscaling** acontecendo em tempo real. Vou abrir **3 terminais**:"

### Terminal 1 â€” Monitoramento do HPA
```bash
kubectl get hpa -n autorepair -w
```
> "Nesse primeiro terminal, estou monitorando o **HPA em tempo real**. Ele mostra o uso de CPU e memÃ³ria atual versus o target, e quantas rÃ©plicas estÃ£o rodando. Agora temos **2 rÃ©plicas** com CPU em **0%**."

### Terminal 2 â€” Monitoramento dos Pods
```bash
kubectl get pods -n autorepair -w
```
> "No segundo terminal, estou monitorando os **pods**. Quando o autoscaling acontecer, vamos ver os novos pods aparecendo aqui â€” passando de **Pending** para **ContainerCreating** e depois **Running**."

### Terminal 3 â€” Gerar Carga
```bash
kubectl run load-generator --image=busybox -n autorepair --restart=Never -- /bin/sh -c "while true; do wget -q -O- http://autorepair-service.autorepair.svc.cluster.local:80/health > /dev/null 2>&1; done"
```
> "E no terceiro terminal, vou **iniciar o teste de carga**. Esse comando cria um pod dentro do cluster que fica fazendo requisiÃ§Ãµes contÃ­nuas ao endpoint `/health` da nossa API. A vantagem de rodar de dentro do cluster Ã© que a latÃªncia Ã© mÃ­nima e a carga Ã© intensa."

### Narrar o que acontece:

> "Reparem no terminal 1: o uso de CPU estÃ¡ subindo... **3%, 9%, 22%, 33%** â€” jÃ¡ ultrapassou o target de 10%.
>
> E agora olhem o terminal 2: o HPA detectou que precisa de mais rÃ©plicas e estÃ¡ criando novos pods. 
> Vejam: `Pending â†’ ContainerCreating â†’ Running`. SaÃ­mos de **2 pods para 4 pods** automaticamente!
>
> Isso Ã© o **Horizontal Pod Autoscaler** do Kubernetes em aÃ§Ã£o â€” ele monitora as mÃ©tricas e **escala horizontalmente** quando a demanda aumenta."

### Parar a carga e mostrar o scale-down:
```bash
kubectl delete pod load-generator -n autorepair
```
> "Agora vou parar o gerador de carga. E em alguns segundos, reparem que o uso de CPU vai cair, e o HPA vai **remover os pods extras**, voltando para as **2 rÃ©plicas originais**.
>
> E pronto! O scale-down aconteceu automaticamente. Isso mostra que a aplicaÃ§Ã£o Ã© **resiliente e elÃ¡stica** â€” escala quando precisa e economiza recursos quando a demanda cai."

---

## Encerramento (~1 min)

> "EntÃ£o resumindo o que entregamos na Fase 2:
>
> 1. **Docker** â€” imagem otimizada com multi-stage build
> 2. **Kubernetes** â€” deployment, service com LoadBalancer, HPA para autoscaling
> 3. **Terraform** â€” toda a infra na AWS provisionada como cÃ³digo: VPC, EKS, RDS, ECR
> 4. **CI/CD** â€” pipeline completo: lint, testes, build, push e deploy automatizado
> 5. **Autoscaling** â€” demonstrado ao vivo com teste de carga
>
> Todos os arquivos estÃ£o no repositÃ³rio do GitHub, incluindo a documentaÃ§Ã£o detalhada de como replicar esse ambiente.
>
> Muito obrigado por assistir! Qualquer dÃºvida pode mandar nos comentÃ¡rios. Valeu! ğŸ‘‹"

---

## â±ï¸ Tempo estimado total: ~10 minutos

## ğŸ“‹ Checklist antes de gravar:

- [ ] Cluster EKS rodando (`kubectl get nodes` â†’ Ready)
- [ ] 2 pods Running (`kubectl get pods -n autorepair`)
- [ ] HPA ativo (`kubectl get hpa -n autorepair`)
- [ ] LoadBalancer com URL (`kubectl get svc -n autorepair`)
- [ ] Health check OK (`curl http://<LB_URL>/health`)
- [ ] Pipeline no GitHub com os 3 jobs verdes
- [ ] 3 terminais preparados
- [ ] SessÃ£o do AWS Academy ativa (verifica tempo restante!)
