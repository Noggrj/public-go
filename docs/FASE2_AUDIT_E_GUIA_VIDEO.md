# üîç Auditoria Fase 2 ‚Äî Tech Challenge + Guia para Grava√ß√£o do V√≠deo

---

## 1. Checklist de Requisitos ‚Äî Status Atual

### 1.1 Evolu√ß√£o da Aplica√ß√£o

| Requisito | Status | Evid√™ncia |
|:---|:---:|:---|
| **Clean Code** (nomes claros, coes√£o) | ‚úÖ | Nomes descritivos em todos os handlers/services/domain |
| **Clean Architecture** (separa√ß√£o de camadas) | ‚úÖ | `internal/service/{domain, application, delivery/http, infrastructure}` |
| **Testes unit√°rios** | ‚úÖ | `tests/unit/` ‚Äî 23 arquivos (identity, inventory, platform, service, sharedkernel) |
| **Testes de integra√ß√£o** | ‚úÖ | `tests/integration/` ‚Äî 6 arquivos (service, identity, inventory) |

### 1.2 APIs Obrigat√≥rias

| API | Status | Endpoint | Handler |
|:---|:---:|:---|:---|
| Abertura de OS | ‚úÖ | `POST /admin/orders` | `OrderHandler.Create` |
| Consulta de status da OS | ‚úÖ | `GET /orders/{id}/track` | `OrderHandler.TrackOrder` (p√∫blico) |
| Aprova√ß√£o/Rejei√ß√£o de or√ßamento | ‚úÖ | `POST /orders/{id}/budget-response` | `OrderHandler.ApproveBudget` (webhook) |
| Listagem de OS ativa (prioridade) | ‚úÖ | `GET /admin/orders` | `OrderHandler.ListActive` |
| Atualiza√ß√£o de status via e-mail | ‚úÖ | `PATCH /admin/orders/{id}/status` + `notification/` | `OrderHandler.UpdateStatus` + `console_email_service.go` |

### 1.3 Status da OS (6 estados)

| Status | Constante no c√≥digo |
|:---|:---|
| Recebida | `OrderStatusReceived` |
| Diagn√≥stico | `OrderStatusInDiagnosis` |
| Aguardando Aprova√ß√£o | `OrderStatusAwaitingApproval` |
| Em Execu√ß√£o | `OrderStatusInExecution` |
| Finalizada | `OrderStatusCompleted` |
| Entregue | `OrderStatusDelivered` |

Ordena√ß√£o da listagem: **In Execution > Awaiting Approval > In Diagnosis > Received** (exclui Completed e Delivered). ‚úÖ

### 1.4 Infraestrutura

| Requisito | Status | Localiza√ß√£o |
|:---|:---:|:---|
| **Dockerfile** (multi-stage) | ‚úÖ | `Dockerfile` (builder ‚Üí development ‚Üí production) |
| **docker-compose** (dev local) | ‚úÖ | `docker-compose.yml` (app + PostgreSQL + SonarQube) |
| **K8s Deployments** | ‚úÖ | `k8s/deployment.yaml` (2 replicas, rolling update, probes) |
| **K8s Services** | ‚úÖ | `k8s/service.yaml` + `k8s/db-service.yaml` |
| **K8s ConfigMaps** | ‚úÖ | `k8s/configmap.yaml` |
| **K8s Secrets** | ‚úÖ | `k8s/secret.yaml` (DB_PASSWORD, JWT_SECRET) |
| **K8s HPA** | ‚úÖ | `k8s/hpa.yaml` (CPU 70%, Memory 80%, 2-10 pods) |
| **Terraform ‚Äî VPC** | ‚úÖ | `infra/main.tf` (3 AZs, public/private/database subnets, NAT) |
| **Terraform ‚Äî EKS** | ‚úÖ | `infra/main.tf` (managed node group, IRSA) |
| **Terraform ‚Äî ECR** | ‚úÖ | `infra/main.tf` (lifecycle policy, scan on push) |
| **Terraform ‚Äî RDS** | ‚úÖ | `infra/main.tf` (PostgreSQL 16.1, encrypted, backup) |
| **Terraform ‚Äî docs** | ‚úÖ | `infra/README.md` |

### 1.5 CI/CD

| Etapa do Pipeline | Status | Arquivo |
|:---|:---:|:---|
| Build da aplica√ß√£o | ‚úÖ | `.github/workflows/ci.yml` ‚Äî Job `build-and-test` |
| Execu√ß√£o dos testes | ‚úÖ | Lint (golangci-lint) + test + coverage |
| Build da imagem Docker | ‚úÖ | Job `docker-build-push` (target production) |
| Push para ECR | ‚úÖ | `aws-actions/amazon-ecr-login` + `docker/build-push-action` |
| Deploy no cluster K8s | ‚úÖ | Job `deploy` (kubectl set image + rollout status) |
| Deploy do banco de dados | ‚úÖ | Migrations via pod tempor√°rio no EKS |
| Aplica√ß√£o dos manifestos YAML | ‚úÖ | K8s via `kubectl` no pipeline |
| Release | ‚úÖ | Job `release` (tag + GitHub Release) |

### 1.6 Entreg√°veis (README.md)

| Item | Status | Observa√ß√£o |
|:---|:---:|:---|
| Descri√ß√£o da solu√ß√£o | ‚úÖ | Se√ß√£o principal do README |
| Desenho da arquitetura | ‚úÖ | 2 diagramas Mermaid (infra + m√≥dulos) |
| Instru√ß√µes de execu√ß√£o local | ‚úÖ | Quick Start com `make up` |
| Instru√ß√µes de deploy K8s | ‚úÖ | Instru√ß√µes `kubectl apply -f k8s/` |
| Instru√ß√µes Terraform | ‚úÖ | Se√ß√£o com `terraform init/plan/apply` |
| Link Postman/Swagger | ‚úÖ | `docs/postman_collection.json` + Swagger UI |
| Link para v√≠deo | ‚ö†Ô∏è | **Pendente** ‚Äî precisa gravar e adicionar o link |

---

## 2. Guia Completo para Deploy e Grava√ß√£o do V√≠deo (at√© 15 min)

### üìã Pr√©-requisitos

- Docker Desktop rodando
- AWS CLI configurado (`aws configure`)
- `kubectl` instalado
- `terraform` instalado
- Postman ou equivalente
- Software de grava√ß√£o de tela (OBS Studio, Camtasia, etc.)

---

### üé¨ Roteiro do V√≠deo (Sugest√£o de Tempo)

#### Parte 1 ‚Äî Execu√ß√£o Local + APIs (‚âà 4 min)

```
1. Mostrar a estrutura do projeto no editor (Clean Architecture)
   - internal/service/{domain, application, delivery, infrastructure}
   - Brevemente explicar as camadas

2. Subir ambiente local
   make up                    # Docker compose (app + DB + SonarQube)
   make migrate-docker        # Rodar migrations
   make seed-docker           # Popular dados de teste

3. Mostrar Swagger UI funcionando
   http://localhost:8080/swagger/index.html

4. Fazer login e obter JWT
   POST /auth/login  ‚Üí  {"email":"admin@autorepair.com","password":"admin123"}
```

#### Parte 2 ‚Äî Consumo das APIs (‚âà 4 min)

Mostrar o fluxo completo de uma OS no Postman/Swagger:

```
# 1. Criar OS
POST /admin/orders
Body: { "client_id": "<id>", "vehicle_id": "<id>", "items": [...] }
‚Üí Anotar o "id" retornado

# 2. Consultar status (p√∫blico)
GET /orders/{id}/track
‚Üí Status: "Received"

# 3. Iniciar diagn√≥stico
POST /admin/orders/{id}/diagnosis:start
‚Üí Status: "In diagnosis"

# 4. Enviar or√ßamento (notifica cliente por e-mail/console)
POST /admin/orders/{id}/budget:send
‚Üí Status: "Awaiting approval"

# 5. Aprova√ß√£o externa do or√ßamento (webhook p√∫blico)
POST /orders/{id}/budget-response  ‚Üí  {"approved": true}
‚Üí Status: "In execution"

# 6. Listar ordens ativas (ordena√ß√£o por prioridade)
GET /admin/orders
‚Üí Mostrar que "In Execution" aparece primeiro, Completed/Delivered exclu√≠das

# 7. Finalizar e entregar
POST /admin/orders/{id}/finish    ‚Üí  Status: "Completed"
POST /admin/orders/{id}/deliver   ‚Üí  Status: "Delivered"

# 8. Verificar que a OS sumiu da listagem ativa
GET /admin/orders
```

#### Parte 3 ‚Äî CI/CD (‚âà 2 min)

```
1. Mostrar o arquivo .github/workflows/ci.yml
   - Explicar os 4 jobs: build-and-test ‚Üí docker-build-push ‚Üí deploy ‚Üí release

2. Op√ß√µes para demonstrar:
   a) Mostrar uma execu√ß√£o anterior no GitHub Actions (aba "Actions" do repo)
   b) OU fazer um push para main e mostrar o pipeline iniciando
   c) OU mostrar o log de uma run bem-sucedida com os 4 jobs verdes

3. Destacar:
   - Lint (golangci-lint)
   - Testes com coverage
   - Build Docker (multi-stage, target production)
   - Push ECR + Deploy EKS
```

#### Parte 4 ‚Äî Deploy Local em Kubernetes com Kind (‚âà 3 min)

> **Passo a passo testado e funcionando** ‚Äî comandos exatos usados com Docker Desktop + Kind.

**Etapa 1 ‚Äî Criar cluster Kind no Docker Desktop**

```
Docker Desktop ‚Üí Settings ‚Üí Kubernetes ‚Üí Create Kubernetes Cluster ‚Üí Kind
  - Nodes: 1
  - Version: 1.31.1
  - Clicar "Create" e aguardar ficar pronto
```

**Etapa 2 ‚Äî Verificar o cluster**

```bash
kubectl get nodes
kubectl cluster-info
```

**Etapa 3 ‚Äî Buildar a imagem de produ√ß√£o**

```bash
docker build --target production -t autorepair:latest .
```

**Etapa 4 ‚Äî Carregar imagens no cluster Kind**

O Kind n√£o compartilha imagens com o Docker host. √â preciso copiar manualmente:

```bash
# Salvar imagem da API como .tar
docker save autorepair:latest -o tmp/autorepair.tar

# Copiar para o node worker do Kind e importar
docker cp tmp/autorepair.tar desktop-worker:/autorepair.tar
docker exec desktop-worker ctr -n k8s.io images import /autorepair.tar

# Fazer o mesmo com o PostgreSQL
docker pull postgres:16-alpine
docker save postgres:16-alpine -o tmp/postgres16.tar
docker cp tmp/postgres16.tar desktop-worker:/postgres16.tar
docker exec desktop-worker ctr -n k8s.io images import /postgres16.tar
```

> ‚ö†Ô∏è **Importante**: Os manifestos K8s j√° est√£o com `imagePullPolicy: Never` para usar imagens locais.

**Etapa 5 ‚Äî Aplicar os manifestos Kubernetes**

```bash
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/
```

Resultado esperado:
```
namespace/autorepair created
configmap/autorepair-config created
secret/autorepair-secret created
persistentvolumeclaim/postgres-pvc created
deployment.apps/postgres created
service/postgres-service created
deployment.apps/autorepair-api created
service/autorepair-service created
horizontalpodautoscaler.autoscaling/autorepair-hpa created
```

**Etapa 6 ‚Äî Rodar as migrations no banco K8s**

```bash
# Port-forward para o PostgreSQL do K8s
kubectl port-forward svc/postgres-service 5434:5432 -n autorepair

# Em outro terminal, rodar migrations via Docker
docker run --rm --network host -v ${PWD}/migrations:/migrations migrate/migrate -path=/migrations/ -database "postgres://postgres:postgres@host.docker.internal:5434/autorepair?sslmode=disable" up
```

**Etapa 7 ‚Äî Verificar que tudo est√° funcionando**

```bash
# Checar pods (todos devem estar Running 1/1)
kubectl get pods -n autorepair

# Checar servi√ßos
kubectl get svc -n autorepair

# Checar HPA
kubectl get hpa -n autorepair

# Port-forward da API
kubectl port-forward svc/autorepair-service 9090:8080 -n autorepair

# Testar health (em outro terminal)
curl http://localhost:9090/health
# ‚Üí {"status":"ok"}
```

**Etapa 8 ‚Äî Testar login e APIs via Postman**

Use `http://localhost:9090` como base URL no Postman:

```
POST http://localhost:9090/auth/login
Body: {"email":"admin@autorepair.com","password":"admin123"}
```

---

#### Parte 4B ‚Äî Deploy na AWS com Terraform + EKS (Cloud)

> **Passo a passo para provisionamento real na nuvem AWS.**

**Pr√©-requisitos AWS:**
- AWS CLI configurado (`aws configure`)
- Conta AWS com permiss√µes para VPC, EKS, RDS, ECR, IAM
- Terraform instalado

**Etapa 1 ‚Äî Provisionar a infraestrutura com Terraform**

```bash
cd infra

# Copiar e preencher as vari√°veis
cp terraform.tfvars.example terraform.tfvars
# Editar terraform.tfvars com suas credenciais:
#   - db_password     = "sua-senha-segura"
#   - jwt_secret      = "seu-jwt-secret"
#   - db_username     = "postgres"
#   - db_name         = "autorepair"
#   - cluster_name    = "autorepair-cluster"

# Inicializar, planejar e aplicar
terraform init
terraform plan      # Revisar os recursos que ser√£o criados
terraform apply     # Confirmar com "yes"
```

Recursos provisionados pelo Terraform:

| Recurso | Descri√ß√£o |
|:---|:---|
| **VPC** | 3 AZs, subnets p√∫blicas/privadas/database, NAT Gateway |
| **EKS** | Cluster Kubernetes gerenciado com node group auto-scaling |
| **ECR** | Registro de containers com lifecycle policy |
| **RDS** | PostgreSQL 16, encrypted, backup autom√°tico 7 dias |
| **K8s Namespace** | `autorepair` criado automaticamente |
| **K8s Secret/ConfigMap** | Credenciais e config injetados via Terraform |

**Etapa 2 ‚Äî Configurar kubectl para o EKS**

```bash
aws eks update-kubeconfig --region us-east-1 --name autorepair-cluster
kubectl get nodes  # Verificar que os nodes est√£o Ready
```

**Etapa 3 ‚Äî Push da imagem para ECR**

```bash
# Login no ECR
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com

# Build e tag
docker build --target production -t autorepair:latest .
docker tag autorepair:latest <ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com/autorepair:latest

# Push
docker push <ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com/autorepair:latest
```

> Substitua `<ACCOUNT_ID>` pelo ID da sua conta AWS. Obtenha com: `aws sts get-caller-identity`

**Etapa 4 ‚Äî Ajustar manifestos K8s para produ√ß√£o**

No `k8s/deployment.yaml`, ajustar a imagem para o ECR:
```yaml
image: <ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com/autorepair:latest
imagePullPolicy: Always
```

> Os ConfigMaps e Secrets j√° s√£o criados pelo Terraform com os valores do RDS.

**Etapa 5 ‚Äî Aplicar manifestos e migrations**

```bash
# Aplicar manifestos (namespace j√° foi criado pelo Terraform)
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
kubectl apply -f k8s/hpa.yaml
kubectl apply -f k8s/db-deployment.yaml  # Opcional: s√≥ para dev. Em prod, usar RDS
kubectl apply -f k8s/db-service.yaml

# Rodar migrations via pod tempor√°rio
kubectl run migrate-job --rm -i --restart=Never \
  --namespace=autorepair \
  --image=<ACCOUNT_ID>.dkr.ecr.us-east-1.amazonaws.com/autorepair:latest \
  --env="DB_URL=<RDS_CONNECTION_STRING>" \
  -- /bin/sh -c "migrate -path /root/migrations -database \$DB_URL up"
```

**Etapa 6 ‚Äî Verificar e acessar**

```bash
kubectl get pods -n autorepair
kubectl get svc -n autorepair
kubectl get hpa -n autorepair

# Obter a URL do Load Balancer (se configurado)
kubectl get svc autorepair-service -n autorepair -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'
```

**Etapa 7 ‚Äî Destruir infraestrutura (quando terminar)**

```bash
cd infra
terraform destroy   # Confirmar com "yes"
```

> ‚ö†Ô∏è **IMPORTANTE**: Destrua a infra AWS ap√≥s gravar o v√≠deo para evitar custos.

---

#### Parte 5 ‚Äî Escalabilidade Autom√°tica (‚âà 2 min)

```bash
# Mostrar HPA configurado
kubectl get hpa -n autorepair
kubectl describe hpa autorepair-hpa -n autorepair
# ‚Üí min: 2, max: 10, CPU target: 70%, Memory target: 80%

# Instalar metrics-server (necess√°rio para Kind/local)
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
# Para Kind, pode ser necess√°rio adicionar --kubelet-insecure-tls ao metrics-server

# Simular carga (em outro terminal, com port-forward ativo)
# Op√ß√£o 1: PowerShell
1..500 | ForEach-Object -Parallel { Invoke-WebRequest -Uri http://localhost:9090/health -UseBasicParsing } -ThrottleLimit 50

# Op√ß√£o 2: usando hey (instalar: go install github.com/rakyll/hey@latest)
hey -z 60s -c 50 http://localhost:9090/health

# Observar o escalonamento em tempo real
kubectl get hpa -n autorepair -w
# ‚Üí REPLICAS vai subir de 2 para 3, 4, etc.

kubectl get pods -n autorepair -w
# ‚Üí Novos pods aparecendo automaticamente
```

---

### üéØ Checklist Final Antes de Entregar

- [ ] V√≠deo gravado (‚â§ 15 min) demonstrando todos os pontos acima
- [ ] V√≠deo publicado no YouTube/Vimeo (p√∫blico ou n√£o listado)
- [ ] `README.md` atualizado com link do v√≠deo
- [ ] Reposit√≥rio Git limpo (sem `terraform.tfvars` com secrets, sem `.env` real)
- [ ] Postman Collection atualizada em `docs/postman_collection.json`
- [ ] Swagger acess√≠vel em `/swagger/index.html`
- [ ] Todos os testes passando (`make test-unit` + `make test-integration`)
- [ ] Infraestrutura AWS destru√≠da ap√≥s gravar o v√≠deo (`terraform destroy`)

---

### ‚ö° Comandos R√°pidos de Refer√™ncia

| A√ß√£o | Comando |
|:---|:---|
| **Ambiente Local (Docker Compose)** | |
| Subir ambiente local | `make up` |
| Rodar migrations | `make migrate-docker` |
| Seed de dados | `make seed-docker` |
| Parar tudo | `make down` |
| **Testes** | |
| Testes unit√°rios | `make test-unit` |
| Testes de integra√ß√£o | `make test-integration` |
| Coverage completo | `make test-cover` |
| Lint | `make lint` |
| **Docker** | |
| Build produ√ß√£o | `docker build --target production -t autorepair:latest .` |
| **Kubernetes Local (Kind)** | |
| Aplicar manifestos | `kubectl apply -f k8s/` |
| Ver pods | `kubectl get pods -n autorepair` |
| Ver HPA | `kubectl get hpa -n autorepair` |
| Port-forward API | `kubectl port-forward svc/autorepair-service 9090:8080 -n autorepair` |
| Port-forward DB | `kubectl port-forward svc/postgres-service 5434:5432 -n autorepair` |
| Reiniciar API | `kubectl rollout restart deployment/autorepair-api -n autorepair` |
| Ver logs API | `kubectl logs deployment/autorepair-api -n autorepair --tail=30` |
| **AWS (Terraform)** | |
| Provisionar infra | `cd infra; terraform init; terraform plan; terraform apply` |
| Conectar ao EKS | `aws eks update-kubeconfig --region us-east-1 --name autorepair-cluster` |
| Destruir infra | `cd infra; terraform destroy` |
